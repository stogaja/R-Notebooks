---
title: "Kira Plastinina Customer Analysis"
author: "STEPHEN ODHIAMBO OGAJA"
date: '2022-06-05'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Problem Definition

### a) Specifying the Question

What are the customer behaviours of different customer groups?

### b) Defining the metric of success

The project will be considered a success when we can accurately come up with an understanding of the different customer groups and their characteristics.

### c) Understanding the context

Kira Plastinina (https://kiraplastinina.ru/) is a Russian brand that is sold through a defunct chain of retail stores in Russia, Ukraine, Kazakhstan, Belarus, China, Philippines, and Armenia. The brand’s Sales and Marketing team would like to understand their customer’s behavior from data that they have collected over the past year. More specifically, they would like to learn the characteristics of customer groups.

### d) Recording the experimental design

    1. Data sourcing/loading
    2. Data Understanding
    3. Data Relevance
    4. External Dataset Validation
    5. Data Preparation
    6. Univariate Analysis
    7. Bivariate Analysis
    8. Multivariate Analysis
    9. Implementing the solution
    10. Challenging the solution
    11. Conclusion
    12. Follow up questions

### e) Data Relevance

For the data to be relevant it should be able to provide meaningful insights that can be used to learn the customer behavours of the different customer groups and their characteristics.


## 2. Data Sourcing

### Libraries
```{r}
#install.packages('VIM')
#install.packages('CatEncoders')
library(CatEncoders)
```

```{r}
#install.packages("readxl")
library(readxl)
```


```{r}
# let's load the required libraries
library(dplyr)
library(readr)
library(data.table)
#install.packages("e1071")
library(e1071)
library(magrittr)
library(knitr)
library(tidyverse)
#install.packages("factoextra")
library(factoextra)
#install.packages("devtools")
library(devtools)
#install.packages("Hmisc")
library(Hmisc)
library(corrplot)
library(CatEncoders)
```

#### a) Reading the Data
```{r}
library(data.table)
shopping <- fread("http://bit.ly/EcommerceCustomersDataset")
head(shopping)
```

#### b) Checking the Data
```{r}
# Number of records
cat('Number of rows = ', nrow(shopping), 'and the number of columns = ', ncol(shopping),'.')
```

```{r}
# top dataset preview
head(shopping, 5)
```

```{r}
# bottom dataset preview
tail(shopping, 5)
```

#### c) Checking Datatypes
```{r}
# let's see the structure of the dataset
str(shopping)
```
The columns have the right datatypes

## 3. External Data Validation

The data was provided by the company about the brand and was based on a previous related customer reaction data, there is no reason for external validation

## 4. Data Preparation

### a) Validation

#### Checking to ensure the columns are valid for this analysis
```{r}
colnames(shopping)
```
The columns are valid

#### let's check for invalid values/ Anomalies
```{r}
# let's see the dataset summary
summary(shopping)
```
There are no anomalies, but we have some missing values

### b) Consistency
```{r}
# checking for missing values
colSums(is.na(shopping))
```
We have some missing values which we will now impute

```{r}
shopping <- na.omit(shopping)
```
We removed all the missing values

### d) Completeness
```{r}
# lets check for duplicates
sum(duplicated(shopping))

# removing duplicates
shop <- distinct(shopping)
```

```{r}
# checking for duplicates
sum(duplicated(shop))
```
The dataset had some duplicated values which we removed

### d) Uniformity
```{r}
# let's check the uniformity of the column names
colnames(shop)
```
The column names are uniform and have no white spaces

#### boxplots for numerical columns to remove outliers
```{r}
num_col <- Filter(is.numeric, shop)
desc_stats <- data.frame(
    min = apply(num_col, 2, min),
    median = apply(num_col, 2, median),
    mean_df = apply(num_col, 2, mean),
    SD = apply(num_col, 2, sd),
    max = apply(num_col, 2, max),
    skew = apply(num_col,2, skewness),
    Kurt = apply(num_col,2, kurtosis)
)

statistics <- round(desc_stats, 1)
statistics
boxplot(num_col, notch = TRUE)
```
The Administrative, BounceRates and Browser columns have outliers but they will be retained for further analysis

## 5. Descriptive Analysis
```{r}
# descriptive statistics
describe(shop)
```

#### Month
The website had the most visitors during the months of May, with 27.3% of total activity for the entire period and november which had 24.5% of all viisits.

#### Browser
53.6% of all visitors were using operating system type 2 while 20.9% were using type 1

#### Region
38.6% of all visitors were from region 1 followed by region 3 which had 19.5% of all visitors

#### Visitor Type
193.9% of the visitors were new visitors while 85.5% were return visitors.

#### Weekend
23.4% of site visits were during the weekend while the rest 76.6% were during the weekdays.

#### Traffic Type
Most of the visitors were directed from traffic type 2 which brought in 32% of all visitors followed by type 1 which brought in 19.5% of all visitors and type 2 wuth 16.5%. Trafic type 12,17 and 16 did not bring in any visitors for the enter duration under analysis.


#### let's make a dataframe of numeric variables for descriptive statistics
```{r}
num_col <- Filter(is.numeric, shop)
desc_stats <- data.frame(
    min = apply(num_col, 2, min),
    median = apply(num_col, 2, median),
    mean_df = apply(num_col, 2, mean),
    SD = apply(num_col, 2, sd),
    max = apply(num_col, 2, max),
    skew = apply(num_col,2, skewness),
    Kurt = apply(num_col,2, kurtosis)
)

statistics <- round(desc_stats, 1)
statistics
```

#### let's plot data distribution histograms for the numerical columns
```{r}
par(mfrow = c(1,2))
for (i in 1:13) {
    hist(num_col[, ..i ], main = names(num_col)[i], xlab = NULL)
}
```

### Analysis on The Revenue Target Column
```{r}
# let's select the revenue column
Revenue <- shop[shop$Revenue == TRUE]

# let's have plots that show customer behaviour
par(mfrow = c(1,2))
for (i in 1:18) {
    barplot(table(Revenue[, ..i]),main = names(Revenue)[i], xlab = names(Revenue)[i])
}
```

#### Descriptive Statistics for the Revenue column
```{r}
describe(Revenue)
```

The website had the most revenue during the months of Nov, with 39.8% of total activity for the entire period and november which had 19.1% of all viisits.

60.5% of all revenue were visitors using operating system type 2 while 19.9% were using type 1

Browser 2 had brought in the most revenue with 64.4% while browser 1 brough in 19.1% of the revenue.

40.4% of all revenue were from region 1 followed by region 3 which had 18.3% of all revenue

Most of the revenue came from traffic type 2 which brought in 44.4% of all revenue followed by type 1 which brought in 13.7% of all revenue.

22.1% of the revenue was from new visitors while 77% were return visitors.

26.2% of site revenue was gained during the weekend while the rest 73.8% was gained during the weekdays.


### Analysis on the near holiday revenues
```{r}
holiday <- shop[shop$SpecialDay > 0,]
par(mfrow = c(1,2))
for (i in 1:18) {
    barplot(table(holiday[, ..i]),main = names(holiday)[i], xlab = names(holiday)[i])
}
```

#### Descriptive Statistics for the near holiday column
```{r}
describe(holiday)
```


### Revenue in region 1
```{r}
region <- shop[shop$Region == 1,]
par(mfrow = c(1,2))
for (i in 1:18) {
    barplot(table(region[, ..i]),main = names(region)[i], xlab = names(region)[i])
  
}
```

#### descriptive statistics for region
```{r}
describe(region)
```

Here's our findings from the most popular region 1 on customer behavior:
Most popular months for visitors from region 1 are March, May and November.

52.3% of all visitors using operating system type 2 while 22.3% were using type 1

Browser 2 had brought in the most visitors with 62.9% while browser 1 brough in 14.3% of the visitors.

16.4% of all visitors from region one brought in revenue.

Trffic type 1,2 and 3 bring in the most number of visitors from region 1 with type 2 being the highest at 32.6%.

13.9% of the visitors was from new visitors while 85.9% were return visitors.

22.7% of site visitors was gained during the weekend while the rest 77.3% was gained during the weekdays.


### Correlation Analysis
```{r}
pairs(num_col, pch = 19)
```


### let's get the Correlation Coefficients
```{r}
cor(num_col)
```

#### Corrplot
```{r}
corrplot(cor(num_col), type = 'upper', method = 'number', tl.cex = 0.6)
```

The variables can be seen to have very weak correlations

## Let's Perform Clustering

#### removing revenue from the clustering dataset as it is the class label
```{r}
# normalizing the data
web_traffic <- num_col
web_traffic[,c('Revenue')]<- list(NULL)

# previewing
head(web_traffic)
```

```{r}
web_traffic <- scale(web_traffic)
head(web_traffic)
```

## KMeans Clustering

### let's find the best value for k
```{r}
fviz_nbclust(x = web_traffic,FUNcluster = kmeans, method = 'wss' )
```

#### let's find the optimal clusters k using (average silhouette method)
```{r}
# optimal values using average silhouette method

fviz_nbclust(x = web_traffic,FUNcluster = kmeans, method = 'silhouette' )
```

The best value for k from the graph is 3

```{r}
# let's test with a few values for k
data_K3 <- kmeans(web_traffic, centers = 2, nstart = 50)
data_K4 <- kmeans(web_traffic, centers = 3, nstart = 50)
data_K5 <- kmeans(web_traffic, centers = 4, nstart = 50)
data_K6 <- kmeans(web_traffic, centers = 5, nstart = 50)

#lets plot these clusters for different K value to compare.
library(gridExtra)
p1 <- fviz_cluster(data_K3, geom = "point", data = web_traffic) + ggtitle(" K = 2")
p2 <- fviz_cluster(data_K4, geom = "point", data = web_traffic) + ggtitle(" K = 3")
p3 <- fviz_cluster(data_K5, geom = "point", data = web_traffic) + ggtitle(" K = 4")
p4 <- fviz_cluster(data_K6, geom = "point", data = web_traffic) + ggtitle(" K = 5")

grid.arrange(p1, p2, p3, p4, nrow = 2)
```

```{r}
set.seed(123)
# let's compute kmeans clusters
data_kmns1 <- kmeans(num_col, centers = 1, nstart = 25)
print(data_kmns1)
```

#### let's add clusters to our dataset as cols
```{r}
compilation <- shop %>%
    mutate(cluster = data_kmns1$cluster) %>%
    select(Revenue, cluster)
head(compilation)
```

```{r}
# let's match the cluster categories to the revenue for comparison
compilation$cluster[compilation$cluster == 1] <- 'FALSE'
head(compilation)
```

```{r}
# let's compare the revenue to the model cluster
table(compilation$cluster == compilation$Revenue)

```

Using the revenue column for comparison, the model was able to match the revenue column with an accuracy of 83.3% which constituted 10,291 columns correctly matched.



## Hierarchical Clustering

```{r}
# let's calculate the distance

## methods to assess
#m <- c( "average", "single", "complete", "ward")
#names(m) <- c( "average", "single", "complete", "ward")
#
#library(cluster)
#library(purrr)
#
#library(factoextra)
# computing the coefficient with a function
#ac <- function(x) {
#    agnes(web_traffic, method = x)
#}
#
#map_dbl(m, ac)
```

```{r}
# calculating distances between observations
dist_euc <- dist(web_traffic, method = 'euclidean')

# computing the manhattan distance between observarions
dist_man <- dist(web_traffic, method = "manhattan")
```


```{r}
#use R's cutree() function to cut the tree with hclust_avg as one parameter and the other parameter as h = 3
hc.avg <- hclust(dist_euc, method = "ward.D2")
cut_avg <- cutree(hc.avg, k = 2)

plot(hc.avg)
rect.hclust(hc.avg , k = 2, border = 5:6)
abline(h = 4, col = 'red')
```

```{r}
# using ward's method
hc5 <- hclust(dist_euc, method = "ward.D2" )

# Cut tree into 2 groups
sub_grp <- cutree(hc5, k = 2)

# Number of members in each cluster
table(sub_grp)
```

```{r}
# Ward's method
hc_complete <- hclust(dist_euc, method = "complete" )

# Cut tree into 2 groups
sub_grp3 <- cutree(hc_complete, k = 2)

# Number of members in each cluster
table(sub_grp3)
```

```{r}
# Ward's method
hc_avg <- hclust(dist_euc, method = "average" )

# Cut tree into 2 groups
sub_grp2 <- cutree(hc_avg, k = 2)

# Number of members in each cluster 
table(sub_grp2)
```

```{r}
# Ward's method
hc_complete <- hclust(dist_man, method = "ward.D2" )

# Cut tree into 2 groups
sub_grp3 <- cutree(hc_complete, k = 2)

# Number of members in each cluster
table(sub_grp3)
```

```{r}
hcomp <- shop %>%
  mutate(cluster = sub_grp) %>%
  head
```

```{r}
# Adding the clusters as a column to our original dataset

hcomp <- shop %>%
  mutate(cluster2 = sub_grp) %>%
  select(Revenue, cluster2) 
tail(hcomp, n= 10)
```

```{r}
# Matching the cluster categories to the revenue for comparison
hcomp$cluster2[hcomp$cluster2 == 2] <- 'FALSE'
hcomp$cluster2[hcomp$cluster2 == 1] <- 'TRUE'
head(hcomp)
```

```{r}
#Comparing the revenue and the model cluster to see if the clusters match
table(hcomp$cluster == hcomp$Revenue)
```

On model clustering using the revenue column as our comparison, the model was able to match the revenue column with a 76.8% accuracy score and we had 9375 columns matched correctly. This is a slight decline from the kmeans model.

## Conclusion

* Mothers day holiday brought in more revenue than Valentines day.
* Most of the wed visits were during the month of May but November had more revenue than may.
* Most of the traffic and revenue was from region 1. During the holidays, more regions visit the site and contribute significantly to the total revenue.
* Traffic type 2 brought in the most visitors. Some of the traffic types did not bring in any visitors for all the 10 months under analysis.They should be eliminated when considering advertisement or re evaluated to find out the problem.
* Most of the revenue and visits was from return visitors. A good indicator of customer satisfaction.

* Return customers are the main source of revenue

* Bounce rate is high especial for new customers.
* Most of the site visits did not bring forth revenue